## 摘要
作为人们日常生活中不可或缺的一部分，社交媒体正成为自动化心理健康分析的重要数据源。传统的判别式方法具有较差的泛化能力和较低的可解释性，近年来，大型语言模型（LLMs）已被用于社交媒体上的可解释心理健康分析，旨在在零样本或少样本场景下，除了预测结果，还能提供详细的解释。然而，研究结果显示，LLMs在零样本/少样本方式下的分类性能仍不理想，这也显著影响了生成解释的质量。领域特定的微调是一种有效的解决方案，但面临两个关键挑战：1）缺乏高质量的训练数据；2）没有开源的基础LLM模型。

为缓解这些问题，我们将可解释心理健康分析正式建模为文本生成任务，并构建了首个多任务、多来源的可解释心理健康指令（IMHI）数据集，包含10.5万条数据样本，用以支持LLM的指令微调和评估。原始社交媒体数据来自于覆盖8个心理健康分析任务的10个现有数据源。我们通过专家设计的少样本提示语，对ChatGPT进行提示以获得解释。为确保解释的可靠性，我们对生成数据的正确性、一致性和质量进行了严格的自动化和人工评估。

基于IMHI数据集和LLaMA2基础模型，我们训练了MentaLLaMA，这是首个面向社交媒体可解释心理健康分析的开源指令遵循型LLM系列。我们在IMHI基准上对MentaLLaMA和其他先进方法进行了评测，IMHI是首个针对可解释心理健康分析的全面评测基准。结果表明，MentaLLaMA在正确性上可接近最先进的判别式方法，并且能够生成达到人类水平的解释。MentaLLaMA模型还在未见任务上展现出强大的泛化能力。项目地址为：https://github.com/SteveKGYang/MentaLLaMA。

## 关键词
心理健康分析、可解释性、社交媒体、大型语言模型

### ACM参考格式：
Kailai Yang, Tianlin Zhang, Ziyan Kuang, Qianqian Xie, Jimin Huang, 和 Sophia Ananiadou. 2024. MentaLLaMA: 基于大型语言模型的社交媒体可解释心理健康分析. 载于2024年ACM Web大会论文集（WWW ’24），2024年5月13-17日，新加坡。ACM, 纽约, 美国, 13页。https://doi.org/10.1145/XXXXXX.XXXXXX

## 1 引言
与心理健康相关的问题正对全球公共健康构成日益严重的威胁[9]，但由于社会认知的缺乏和污名化现象的存在，这些问题仍被低估[31]。随着网络技术的发展，社交媒体已经成为人们日常生活中不可或缺的一部分¹。许多有潜在心理健康问题的人会在Twitter和Reddit等社交媒体平台上分享自己的感受，这使得社交媒体文本成为心理健康分析和潜在早期干预的重要数据来源[2, 36]。然而，面对社交媒体帖子数量的爆炸式增长，人工进行心理健康分析已变得不可能。因此，许多研究开始探索利用自然语言处理（NLP）技术在社交媒体上实现自动化心理健康分析[10]。

在心理健康的NLP研究中，以往的方法主要将社交媒体上的心理健康分析建模为文本分类任务，其中预训练语言模型（PLMs）[19]达到了最先进（SOTA）的性能。然而，PLMs在应对未见任务时往往泛化能力较差，并且在多任务场景下缺乏鲁棒性[26, 39]。这些方法的另一个主要局限是，它们做出的判别性预测可解释性较低，限制了其在实际应用中的可靠性。为缓解这些问题，最新的大型语言模型（LLMs），如ChatGPT²和GPT-4[29]，已被用于检测多种心理健康状况并为其决策提供详细解释，因为它们被证明拥有更强的泛化能力[4, 42]。具体来说，Yang等人[45]进行了综合研究和细致的人类评估，表明ChatGPT具有很强的上下文学习能力，并且能够为其正确分类生成接近人类水平的解释，这显示出其提升心理健康分析可解释性的潜力。

然而，像ChatGPT这样的闭源大型语言模型（LLM）在零样本[1]或少样本[44]学习环境下，仍难以达到最先进（SOTA）监督方法在心理健康分类任务上的表现。此外，这种较低的精度被证明会进一步显著影响生成解释的质量，即所谓的不准确推理[45]。一种有效的解决方案是利用任务特定的数据对LLM进行微调[15, 43]，这可以更好地使LLM与目标领域对齐，同时保持较强的泛化能力。然而，在通过微调提升LLM在可解释心理健康分析方面的表现时，存在两个关键挑战。

首先，微调LLM需要高质量的有监督训练数据。在社交媒体上的心理健康分析中，尽管已有一些数据集包含了简短的随意文本片段[11, 12]，但仍缺乏公开的、高质量的能够为检测结果提供详细且可靠解释的数据。这主要是由于该研究主题的敏感性[3, 28]，以及由领域专家撰写解释的高昂成本所致。

其次，对闭源LLM（如ChatGPT）进行提示或微调不仅成本高昂³、耗时长，还伴随着巨大的碳排放⁴，同时，目前尚未有面向可解释心理健康分析的开源LLM对外发布。资源的匮乏和高昂的成本阻碍了相关研究的进展。

首先，微调LLM需要高质量的有监督训练数据。在社交媒体上的心理健康分析任务中，尽管已有少量数据集包含了简短的随意文本片段[11, 12]，但仍然缺乏能够为检测结果提供详细且可靠解释的开源数据。这主要是由于该研究主题的敏感性[3, 28]，以及由领域专家撰写解释所需的高昂成本所致。

其次，对闭源LLM（如ChatGPT）进行提示或微调不仅成本高、耗时长，还伴随着巨大的碳排放，同时，目前尚未有面向可解释心理健康分析的开源LLM对外发布。资源的缺乏和高昂的成本阻碍了相关研究的进展。

为弥补这些不足，我们将可解释心理健康分析正式建模为一个文本生成任务，旨在检测社交媒体帖子中的心理健康状况证据，并为预测结果生成解释。我们构建了首个多任务、多来源的可解释心理健康指令（IMHI）数据集，包含10.5万条数据样本，用以支持LLM的指令微调[30]和评估。

首先，我们从10个现有数据源中收集了原始数据，覆盖了8个心理健康分析任务。所收集的数据包括社交媒体帖子及其对应的心理健康相关任务标注。其次，受self-instruct方法[41]成功经验的启发，并考虑到ChatGPT在为心理健康分析生成接近人类水平解释方面的巨大潜力[45]，我们利用专家编写的少样本示例和收集到的标注，来提示ChatGPT为每个标注生成高质量的解释。为确保解释的质量，我们对所有收集到的数据进行了全面的自动化评估，评估内容包括预测的正确性、标注与解释之间的一致性以及解释的质量。我们还针对部分数据，采用领域专家精心设计的标注方案进行了人工评估。第三，我们将所有收集到的社交媒体帖子、标注和解释，按照规则转换为基于指令的问答对，这些数据用于构建IMHI训练集和IMHI评测基准，这也是首个面向可解释心理健康分析任务的全面评测基准。

基于IMHI数据集，我们提出了MentaLLaMA，这是首个基于LLaMA2基础模型[35]、具备指令遵循能力的开源可解释心理健康分析大模型系列。具体来说，我们微调了三种不同规模的MentaLLaMA模型：MentaLLaMA-7B、MentaLLaMA-chat-7B和MentaLLaMA-chat-13B（图1中展示了MentaLLaMA强大能力的部分示例）。我们在IMHI评测基准上对MentaLLaMA模型及其他先进方法进行了全面评估，重点关注心理健康检测的正确性和生成解释的质量。结果显示，MentaLLaMA-chat-13B在10个测试集中的7个上，其预测正确性超过或接近最先进的判别式方法[19]，且MentaLLaMA生成的解释与ChatGPT相当，始终优于生成式预训练语言模型（PLM）。其生成质量得益于指令微调、人类反馈强化学习（RLHF）[34]以及模型规模的提升。MentaLLaMA模型还展现出对未见任务的强大泛化能力，在预测正确性上优于ChatGPT，在解释质量上也超过生成式PLM。

我们的主要贡献总结如下： 1）我们正式定义了可解释心理健康分析任务，并构建了IMHI数据集，这是第一个面向社交媒体可解释心理健康分析的多任务、多来源指令微调数据集。 2）我们提出了MentaLLaMA，这是首个面向可解释心理健康分析的开源指令遵循大语言模型系列。 3）我们引入了首个包含1.9万测试样本的全面评测基准，覆盖8个任务和10个测试集。 4）我们在该基准上的实验结果和分析表明，MentaLLaMA在预测正确性、生成解释的质量和泛化能力方面均具有明显优势。

### 2 任务形式化
基于前期探索研究 [44, 45]，我们在本节正式定义了可解释心理健康分析任务。与以往的判别式方法不同，我们将心理健康分析建模为一个生成任务，其中生成模型（如自回归语言模型𝑃𝜙(𝑦|𝑥)，以预训练权重𝜙为参数）作为基础。该模型能够同时解决𝑁个心理健康分析任务，如心理健康检测和原因检测，并为决策生成解释。

每个任务𝑡由𝑁𝑡个训练上下文-目标对组成的子集表示：
D𝑡 = {(𝑞𝑖 𝑡, 𝑟𝑖 𝑡)}𝑖=1,...,𝑁𝑡
其中，𝑞是包含目标帖子和查询内容的token序列，𝑟则是另一个序列，包括对查询的回答（例如分类结果）及用自然语言表达的决策理由。所有子集最终合并为训练数据集：
D = ∪𝑡=1,...,𝑁 D𝑡
模型在这些数据上进行优化，以最大化条件语言建模目标，从而提升预测的正确性和推理质量

### 3 IMHI 数据集

本节介绍了 IMHI 数据集的构建过程。该过程主要包括四个步骤：原始数据收集、通过 ChatGPT 生成解释、对生成解释的评估，以及指令的构建。

#### 3.1 原始数据收集
原始数据收集自10个现有的心理健康分析数据集，这些数据集来源于多个社交媒体平台，包括Reddit、Twitter和短信（SMS）文本。这些数据集均带有高质量的标注，是生成解释和AIGC评估的重要资源。更多的原始数据统计见下文和表1。

**二分类心理健康检测**
该任务旨在检测某一种心理健康状况的症状，每条社交媒体帖子都被标注为二元标签。我们选用了两个用于抑郁症状检测的数据集：Depression_Reddit（DR）[31] 和 CLPsych15（CLP）[6]。同时还使用了Dreaddit [37]（用于压力检测）以及一个孤独症状检测数据集。

**多分类心理健康检测**
该任务旨在从多个心理健康状况中识别出一种症状，通常被建模为多类别单标签分类任务。我们选用了T-SID [18]和SWMH [18]两个数据集，涵盖了抑郁、PTSD、焦虑等症状。

**心理健康成因/因素检测**
对于表现出心理健康问题的帖子，该任务旨在从给定的成因/因素列表中，为帖子分配一个可能导致心理健康问题的成因标签。常见成因包括社会关系、药物、工作压力等。我们选用了压力成因检测数据集SAD [25]和抑郁/自杀成因检测数据集CAMS [11]。

**心理风险/健康因素检测**
该任务进一步挖掘心理健康问题背后的社会或心理因素，目标是从社交媒体帖子中识别心理风险或健康因素，这同样被建模为检测特定因素是否存在的分类任务。我们选用了IRF [12]，这是一个关于心理障碍人际风险因素的标注数据集。另一个名为MultiWD [33]的数据集也被收集，用于分析基于心理学模型的心理健康维度。

#### 3.2 利用 ChatGPT 生成解释

尽管现有的数据源中有丰富且高质量的分类标注，但缺乏能够为这些标注提供详细且可靠解释的开源数据。因此，我们利用 ChatGPT 为收集到的样本生成解释，ChatGPT 已被证明是一种在可解释心理健康分析中可靠的大型语言模型 [45]。首先，我们邀请领域专家为收集到的10个数据集中的每个任务，手动编写1条任务特定的指令和35条解释示例。专家编写的解释构成了一个包含350个样本的黄金解释集 G。为便于模型训练和评估，所有专家编写的解释都基于以下模板：
[label] Reasoning: [explanation]
其中 [label] 表示分类标注，[explanation] 表示相应的解释内容。其次，对于每个数据集，我们为每个类别从G中随机抽取2个解释，并将其作为few-shot示例包含在提示词中。为了进一步提升生成质量，我们还引入了原始数据集中的有监督标注。第三，我们结合任务特定的指令、少量专家编写的示例和目标帖子的分配标注，共同构建ChatGPT生成解释的提示词。数据集DR的提示词示例如图2所示，其他数据集的提示词示例见附录的表6。

#### 3.3 解释质量评估

我们对ChatGPT生成的解释进行了全面评估，以确保其质量。由于生成的解释数量庞大（共计10.5万条），我们对所有收集到的数据进行了整体的自动化评估，并从中选取了部分数据进行人工评估。

**3.3.1 自动化评估**
在自动化评估中，我们认为有三个标准对保证生成解释的质量至关重要：
1）正确性（Correctness）：解释在对应的心理健康分析任务中应当能够做出正确的标签预测。
2）一致性（Consistency）：解释应当能够提供与其预测标签一致的线索和分析 [40]。
3）质量（Quality）：从心理学角度来看，生成的解释应在可靠性、专业性等方面提供有力的支持证据 [45]。
基于以上定义，我们为每个标准设计了自动化评估方法，具体如下：

- 正确性
在解释生成过程中，我们将每个收集数据集的标注标签结合进提示词中，以监督ChatGPT生成正确的解释。一个合理的假设是：当数据集标注与ChatGPT预测的分类结果一致时，该分类结果可以视为正确。然而，我们注意到，ChatGPT有时会在回答中表达对指定标签的不认同。此类不一致的例子见附录C.2。造成这些分歧的原因，可能是部分任务的主观性较强，以及部分数据集采用了弱监督标注流程（见表1）。在这些情况下，我们请领域专家手动检查提示和回复，对分类及解释进行修改或重写。我们在图3(a)中展示了每个数据集的数据标注与ChatGPT之间的一致性比例。结果显示，10个数据集中有7个的一致性比例超过90%，说明大多数生成回复具有较高的正确性。T-SID数据集的一致性比例低于70%，原因是其标签是通过对Reddit子版块聚类获得的弱监督标签[18]。loneliness和IRF数据集的一致性也低于80%，因为它们是基于如孤独感检测和人际风险因素识别等主观性较强的任务构建的。

- 一致性
由于所有ChatGPT生成内容都遵循3.2节指定的模板，一致性评估考察每条回复中[explanation]中的证据是否支持[label]。具体而言，我们通过“Reasoning:”分割每条回复中的[explanation]和[label]内容，并利用ChatGPT在各训练集划分中的[explanation]和[label]对，基于MentalBERT [19]训练一个分类器。对于第i条解释[explanation]𝑖，我们有：

其中 ([label]_i^p = MentalBERT([explanation]_i))。

这里的 ([label]_i^p) 由第 (i) 条标签 ([label]_i) 进行监督。这种方法的直观理解是，一致性更高的训练对能够指导出更精确的分类器，使其能够根据解释内容识别出所支持的标签。为了评估所训练分类器的准确性，我们分别在每个原始数据集测试集上的 ChatGPT 回复，以及专家编写的黄金解释集 (G) 上对其进行了测试。分类性能如图 3(b) 所示。结果显示，所有分类器在测试集回复上的加权 F1 分数均超过 93.5%，表明 ChatGPT 生成的解释与标注标签之间在一致性方面具有非常稳定的分布。

在黄金解释集上的测试结果显示，分类器在 10 个数据集中有 9 个的准确率超过 94%，其中 4 个数据集达到 100% 的表现。这些结果说明，分类器能够非常准确地识别正确的解释与标签对，证明了训练数据（即原始数据集训练集上的 ChatGPT 回复）具有很高的一致性。然而，SAD 数据集的表现相对较低（86.6%）。可能的原因是对于某些标签（例如“学校”和“工作”、“家庭”和“社会关系”），如表1所示，其解释可能具有相似的语义，因此难以区分。基于以上结果，我们可以得出结论：ChatGPT生成的解释与分配的标签具有高度一致性。

- 质量评估
通过细致的人类评价，Yang 等人 [45] 显示 ChatGPT 能够以零样本方式生成接近人类水平的解释，在流畅性、可靠性等方面表现出色。因此，我们将 ChatGPT 的零样本解释作为基线，用于评估我们数据的生成质量。具体而言，基于我们在第 3.2 节设计的提示（称为带标签提示），我们去除分配标签得到少样本提示，再去除分配标签和专家少样本示例后得到零样本提示。我们分别用零样本提示、少样本提示和带标签提示对黄金解释集 G 中的 350 个帖子向 ChatGPT 进行提问。

以 G 中的专家编写解释为黄金标准，我们采用 BART-score [47] 自动评估三种提示下生成结果的质量，因为在可解释心理健康分析领域，BART-score 被证明与人工评价的相关性最高 [45]。评测结果如图 3(c) 所示。根据结果，所有原始数据集中，少样本输出相较于零样本输出有显著提升，证明专家编写的少样本示例对于提升 ChatGPT 生成解释的质量非常有效。此外，带标签提示生成的解释进一步优于零样本输出，且被证明已经接近人类水平。以上证据表明，IMHI 数据集中的解释具有很高的质量。

图表内容解释如下：
- 横轴是四个评估维度：一致性（Consistency）、可靠性（Reliability）、专业性（Professionality）、整体效果（Overall）。
- 纵轴的分数范围从0到3，得分越高代表表现越好。
- 每个维度使用箱线图（boxplot）展示了所有样本的分数分布。
  - 橙色线表示该维度评分的中位数。
  - 绿色点表示该维度评分的平均值。
- 从分布可以看出：
  - 一致性（Consistency）：大多数评分集中在2.5以上，表明大部分解释内容流畅、连贯且与分类结果高度一致。
  - 可靠性（Reliability）：大多数样本得分在2.0以上，大部分解释信息可靠，几乎没有严重的错误。
  - 专业性（Professionality）：得分大多较高，说明解释在心理学角度具备较高的专业性和合理性。
  - 整体效果（Overall）：评价普遍较好，说明整体上解释文本质量较高。
- 说明：极少数打了0分或1分的样本为异常情况，但整体表现非常稳定，得分集中，显示ChatGPT生成的解释文本在大多数情况下在各项维度上都表现优秀。

**3.3.2 人工评估**

我们从原始数据集中随机抽取了200条由ChatGPT生成的解释，进行人工评估。标注方案基于以往相似任务的协议[38, 45]制定，并在两位领域专家（定量心理学博士生）的协作下，针对可解释心理健康分析进行了进一步调整。具体而言，我们从以下四个方面对解释进行评估：
- 1）一致性：文本内容应当句句衔接，形成连贯的信息体，并能支持分类结果；
- 2）可靠性：解释中证据支持分类结果的可信度；
- 3）专业性：从心理学角度衡量生成解释中证据的合理性；
- 4）整体效果：生成解释的总体有效性。
每个方面分为0到3分四个等级，分数越高表示表现越好。更多标注细节见附录B。在标注过程中，每条样本由三位领域专家（定量心理学博士生）在所有维度上独立评分，最终对每条样本的得分取平均值并呈现在图4中。

根据评估结果，大多数解释在一致性方面得分超过2.5，表明这些数据与分类结果高度一致，文本流畅、连贯且无错误。大部分样本在可靠性方面也获得了超过2.0的得分，说明其信息大多可靠，几乎没有严重的错误信息或推理错误。专业性方面的评估结果显示，大多数解释能够从心理学角度给出多项有力证据。总体来看，人工评估表明ChatGPT生成的解释具有良好的整体表现，这与以往分析[45]和自动化评估结果一致。

#### 3.4 指令构建

我们基于所有原始数据集中的帖子及其经过评估的 ChatGPT 生成解释，构建了 IMHI 数据集。我们对第 3.2 节中介绍的指令进行了简化，以适应能力较弱的大语言模型，并以规则化的方式生成问题。这些经过评估的 ChatGPT 生成解释被直接用作这些问题的答案。我们将所有原始数据集训练集中的问答对混合并随机排列，构建了 IMHI 数据集的训练集，共包含 72,095 条样本。为了便于最佳模型的选择，我们还构建了验证集，方法与训练集相同，来源于各原始数据集的验证集，共有 14,346 条样本。

鉴于部分基线模型的指令遵循能力较差，我们还采用另一套模板将 IMHI 数据转换为基于补全形式的数据集，称为 IMHI-completion。IMHI 和 IMHI-completion 数据集的提示模板详见附录 C.1。

### 4 MENTALLAMA 训练
基于 IMHI 数据集，我们对 LLaMA2 [35] 模型进行了微调，构建了我们的 MentaLLaMA 模型。首先，我们通过在 IMHI 训练集上对 LLaMA2-7B 进行 10 轮训练，得到 MentaLLaMA-7B，并根据 IMHI 验证集的结果选择最佳模型。我们设置的 batch size 为 32，梯度累积步数为 8，因此实际 batch size 为 256。模型采用 AdamW 优化器 [24]，最大学习率为 1e-5，warm-up 比例为 3%。最大输入长度设为 2048。我们还采用了 Flash-Attention [7] 以加速训练过程。

其次，我们分别在 LLaMA2-chat-7B 和 LLaMA2-chat-13B 上进行训练，构建了 MentaLLaMA-chat-7B 和 MentaLLaMA-chat-13B。它们通过指令微调 [30] 进行优化，并是首批通过人类反馈强化学习（RLHF）[34] 微调的开源大语言模型。这一训练过程在同样的 IMHI 数据集和实验设置下进行。

第三，为了与以补全形式微调的基线模型进行公平对比，我们还在 IMHI-completion 数据集上训练了另一版 LLaMA2-7B 模型。所有模型均在 4 块 80GB 显存的 Nvidia Tesla A100 GPU 上完成训练。

### 5 IMHI 评测基准

我们基于收集到的数据集的测试集，构建了用于可解释心理健康分析的 IMHI 评测基准。由于每个数据集的数据需要不同的评估指标设置，我们根据数据来源将测试数据分为10个子集。评测基准的统计信息见表1。

遵循第3.3.1节中提出的AIGC评估标准，该基准从两个关键方面评估模型的输出：预测的正确性和解释的质量。我们将预测正确性的评估建模为分类任务，并根据模型输出预测与参考标签之间的加权F1分数进行计算。这种方法的一个主要挑战在于，一些模型，尤其是经过指令微调的模型，生成的回复格式并不统一（不像第3.2节中那样遵循固定模板）。这种不规则的回复使得基于规则的标签判定变得困难。

为了解决这个问题，我们采用了基于MentalBERT的分类器（该方法在第3.3.1节用于评估IMHI数据集一致性），为每个回复分配预测标签。由于这些分类器在IMHI测试集和黄金解释集上的表现良好（见图3(b)），因此预计它们能够准确地根据回复分配标签。在解释质量的评估上，我们沿用第3.3.1节的方法，采用BART-score [47] 对模型输出进行自动化评价。

## 6 实验与分析
### 6.1 基线模型

我们选择了以下强大且具有代表性的基线模型，与我们的 MentaLLaMA 模型进行对比：

**判别式方法。**由于心理健康分析在以往通常被建模为文本分类任务，我们选择了分类模型作为基线模型，其中最新的方法大多是在目标数据集上对判别式预训练语言模型（PLMs），如 BERT [8] 和 RoBERTa [23] 进行微调。我们还包括了 SOTA（当前最优）方法 MentalBERT 和 MentalRoBERTa [19]，这两种模型是在大规模心理健康领域数据上从零预训练语言模型，并进一步在目标数据集上微调。由于这些模型无法生成文本，我们只在正确性对比中使用这些模型。

**零样本/少样本方法。**随着基础大语言模型（LLM）的快速发展，零样本和少样本解决方案已变得高效且具备成本优势。我们选择了开源 LLM LLaMA2 [35] 的 7B 和 13B 版本，在基准数据上进行零样本提示。同时，我们也在闭源 LLM ChatGPT 和 GPT-4 [29] 上进行了零样本和少样本提示实验。

**基于补全的微调方法。**为了评估我们模型的参数效率，我们还在相同训练设置下，对更小规模的生成式 PLM 进行微调。我们选择了当前最优的生成式 PLMs——BART-large [22] 和 T5-large [32]。由于这些 PLM 缺乏强大的指令遵循能力 [30]，我们在 IMHI-completion 数据集上对它们进行微调。为了公平对比，我们也在同一数据集上训练了一版 LLaMA-7B 模型。

### 6.2 IMHI测试结果

#### 6.2.1 正确性
正确性评估结果见表2。在判别式方法中，MentalBERT 和 MentalRoBERTa 仍然在10个测试集中的8个上取得了SOTA（当前最优）表现。考虑到这些模型的体量较小，我们可以得出结论：对于判别式心理健康分析，微调领域专用的预训练语言模型（PLM）依然是最高效的方法。然而，这些方法的主要局限性在于其泛化能力和决策的可解释性较差。它们的能力仅限于原本训练的任务，并且很难理解其决策过程。

在零样本方法的对比中，ChatGPT₍𝑍𝑆₎ 在所有10个数据集上都显著优于LLaMA2模型。这些结果可能归因于大语言模型的“涌现能力”[42]，即在较小模型（如7B、13B LLaMA2）中，心理健康分析能力较弱，但在更大模型（如175B的ChatGPT）中能力会迅速提升。此外，ChatGPT₍𝐹𝑆₎ 和 GPT-4₍𝐹𝑆₎ 在所有测试集上的表现也都优于ChatGPT₍𝑍𝑆₎。这一现象与以往研究[4]一致，即通过专家编写的示例进行上下文学习，可以校准大模型在主观任务上的决策边界。然而，GPT-4在多数数据集上并未表现出对ChatGPT的明显优势。

所有微调方法在所有数据集上的结果都较LLaMA2₍𝑍𝑆₎ 有显著提升，这普遍证明了基于补全/指令的微调方法的有效性。在基于补全的微调方法中，我们意外地发现T5或BART在大多数测试集上都优于LLaMA2-7B，尽管它们的模型体量仅为LLaMA2-7B的15%。可能的原因是，在不自然的IMHI-completion数据集上训练LLaMA2，无法很好地激发其能力。为进一步验证这一假设，我们用IMHI数据集训练了MentaLLaMA-7B。如结果所示，MentaLLaMA-7B在10个测试集中的8个上优于基于补全的LLaMA2-7B，显示出领域专用的指令微调在提升LLaMA2正确性方面比补全微调更高效。

在LLaMA2-chat上的实验进一步证实了这一结论，因为MentaLLaMA-chat-7B和MentaLLaMA-chat-13B在10个测试集中的9个上都优于MentaLLaMA-7B。基于LLaMA2的LLaMA2-chat模型通过高质量的指令微调[30]得到增强，使其能够更好地应对心理健康相关的问题。值得注意的是，MentaLLaMA-chat-13B在10个测试集中的7个上超越或与MentalRoBERTa的差距小于5%，表明其在心理健康分析正确性方面已接近SOTA水平。

#### 6.2.2 质量
我们采用 BART-score 评估结果来衡量解释生成的质量。在补全式方法中（见图5(a)），LLaMA2-7B 在所有10个测试集上都远超 LLaMA2-7B₍𝑍𝑆₎，显示出补全式微调在提升解释质量方面的有效性。T5 和 BART 模型生成的解释得分相近，说明它们在可解释文本生成方面能力相近。LLaMA2-7B 在10个测试集中的9个都优于 BART-large，但优势有限，仅有2个测试集（MultiWD 和 IRF）在 BART-score 上提升超过0.2。这些结果进一步证明了，对 LLaMA2 进行补全式微调并不是高效方案。基于上述观察，我们推荐使用 BART-large 来构建基于补全的可解释心理健康分析模型，因为它既具备较强能力，也具备成本优势。



[6 CLPsych 2015 Shared Task: Depression and PTSD on Twitter](https://aclanthology.org/W15-1204/)

[7 FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness](https://arxiv.org/abs/2205.14135)

[9 Socio-economic variations in the mental health treatment gap for people with anxiety, mood, and substance use disorders: Results from the WHO World Mental Health (WMH) Surveys](https://pmc.ncbi.nlm.nih.gov/articles/PMC6878971/)

[10 Mental Health Analysis in Social Media Posts: A Survey](https://pubmed.ncbi.nlm.nih.gov/36619138/)

[11 CAMS: An Annotated Corpus for Causal Analysis of Mental Health Issues in Social Media Posts](https://aclanthology.org/2022.lrec-1.686/)

[12 An Annotated Dataset for Explainable Interpersonal Risk Factors of Mental Disturbance in Social Media Posts](https://aclanthology.org/2023.findings-acl.757/)

[18 Suicidal Ideation and Mental Disorder Detection with Attentive Relation Networks](https://arxiv.org/abs/2004.07601)

[19 MentalBERT: Publicly Available Pretrained Language Models for Mental Healthcare](https://aclanthology.org/2022.lrec-1.778/)

[24 Decoupled Weight Decay Regularization](https://arxiv.org/abs/1711.05101)

[25 SAD: A Stress Annotated Dataset for Recognizing Everyday Stressors in SMS-like Conversational Systems](https://dl.acm.org/doi/10.1145/3411763.3451799)

[31 Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683)

[33 MultiWD: Multi-label wellness dimensions in social media posts](https://www.sciencedirect.com/science/article/pii/S1532046424000042)

[34 Learning to summarize from human feedback](https://arxiv.org/abs/2009.01325)

[35 Llama 2: Open Foundation and Fine-Tuned Chat Model](https://arxiv.org/abs/2307.09288)

[37 Dreaddit: A Reddit Dataset for Stress Analysis in Social Media](https://aclanthology.org/D19-6213/)

[41 Self-Instruct: Aligning Language Models with Self-Generated Instructions](https://aclanthology.org/2023.acl-long.754/)

[42 Emergent Abilities of Large Language Models](https://arxiv.org/abs/2206.07682)

[45 Towards Interpretable Mental Health Analysis with Large Language Models](https://aclanthology.org/2023.emnlp-main.370/)

[47 BARTScore: Evaluating Generated Text as Text Generation](https://arxiv.org/abs/2106.11520)

其他可供参考文章：
[心理所开发出新型的生活满意度评估方法](https://www.psych.ac.cn/news/kyjz/202410/t20241031_7411463.html)

[利用机器学习预测青少年心理健康风险](https://nursing.sysu.edu.cn/article/3089)
